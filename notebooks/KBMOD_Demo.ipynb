{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from kbmod.fake_data_creator import *\n",
    "from kbmod.run_search import *\n",
    "from kbmod.search import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup file paths and create data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are at least two file paths you need to setup in order to run kbmod:\n",
    "1. The im_filepath provides a path to the input images.\n",
    "1. The res_filepath provides a path to the directory where the output results will be stored.\n",
    "\n",
    "A time and psf file can optimally be specified.\n",
    "\n",
    "If you already have data files, you can use those. Or for the purposes of the notebook, you can generate fake data as in the create_fake_data.ipynb notebook, which is what we do in the code block below. If you want to use your own data simply override these two path variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['000008.fits', '000009.fits', '000010.fits', '000011.fits', '000012.fits', '000013.fits', '000014.fits', '000015.fits', '000016.fits', '000017.fits', '000018.fits', '000019.fits', '000000.fits', '000001.fits', '000002.fits', '000003.fits', '000004.fits', '000005.fits', '000006.fits', '000007.fits']\n"
     ]
    }
   ],
   "source": [
    "im_filepath = \"./fake_data\"\n",
    "ds = FakeDataSet(256, 256, 20)\n",
    "ds.insert_random_object(500)\n",
    "ds.save_fake_data(im_filepath)\n",
    "\n",
    "print(os.listdir(im_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_filepath = \"./fake_results\"\n",
    "if not Path(res_filepath).is_dir():\n",
    "    print(f\"Directory {res_filepath} does not exist. Creating.\")\n",
    "    os.mkdir(res_filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run KBMOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "Loading Images\n",
      "---------------------------------------\n",
      "Loaded 20 images\n",
      "Times set\n",
      "Starting Search\n",
      "---------------------------------------\n",
      "Ecliptic Angle = 1.1901\n",
      "Min. Search Angle = 2.7609\n",
      "Max Search Angle = 5.9025\n",
      "Min Velocity = 0.0000\n",
      "Max Velocity = 50.0000\n",
      "Using in-line GPU sigmaG filtering methods\n",
      "sigmaG limits: [15,60]\n",
      "sigmaG coeff: 0.7753\n",
      "Search finished in 0.451s\n",
      "---------------------------------------\n",
      "Retrieving Results\n",
      "---------------------------------------\n",
      "Getting results...\n",
      "---------------------------------------\n",
      "Chunk Start = 0\n",
      "Chunk Max Likelihood = 4.80\n",
      "Chunk Min. Likelihood = -1.00\n",
      "---------------------------------------\n",
      "Extracted batch of 0 results for total of 0\n",
      "---------------------------------------\n",
      "Applying Stamp Filtering\n",
      "---------------------------------------\n",
      "Skipping. Nothing to filter.\n",
      "---------------------------------------\n",
      "Saving Results\n",
      "---------------------------------------\n",
      "Time taken for patch:  1.1431975364685059\n"
     ]
    }
   ],
   "source": [
    "results_suffix = \"DEMO\"\n",
    "v_min = 0  # Pixels/day\n",
    "v_max = 50\n",
    "# Offset by PI for prograde orbits in lori allen data\n",
    "ang_below = -np.pi + np.pi / 2.0  # Angle below ecliptic\n",
    "ang_above = np.pi + np.pi / 2.0  # Angle above ecliptic\n",
    "v_steps = 50\n",
    "ang_steps = 50\n",
    "\n",
    "v_arr = [v_min, v_max, v_steps]\n",
    "ang_arr = [ang_below, ang_above, ang_steps]\n",
    "\n",
    "num_obs = 15\n",
    "\n",
    "input_parameters = {\n",
    "    # Required\n",
    "    \"im_filepath\": im_filepath,\n",
    "    \"res_filepath\": res_filepath,\n",
    "    \"time_file\": None,\n",
    "    \"output_suffix\": results_suffix,\n",
    "    \"v_arr\": v_arr,\n",
    "    \"ang_arr\": ang_arr,\n",
    "    # Important\n",
    "    \"num_obs\": num_obs,\n",
    "    \"do_mask\": True,\n",
    "    \"lh_level\": 10.0,\n",
    "    \"gpu_filter\": True,\n",
    "    # Fine tuning\n",
    "    \"sigmaG_lims\": [15, 60],\n",
    "    \"mom_lims\": [37.5, 37.5, 1.5, 1.0, 1.0],\n",
    "    \"peak_offset\": [3.0, 3.0],\n",
    "    \"chunk_size\": 1000000,\n",
    "    \"stamp_type\": \"cpp_median\",\n",
    "    \"eps\": 0.03,\n",
    "    \"clip_negative\": True,\n",
    "    \"mask_num_images\": 10,\n",
    "}\n",
    "\n",
    "rs = run_search(input_parameters)\n",
    "rs.run_search()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean up the fake data\n",
    "\n",
    "If fake data was generated, you probably want to clean it up here. Do **not** delete the directory if you are using static data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to delete the fake data.\n",
    "# ds.delete_fake_data(im_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (.conda-kbmod)",
   "language": "python",
   "name": "conda-env-.conda-kbmod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
