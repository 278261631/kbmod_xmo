{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "from astropy.io import fits\n",
    "from sklearn.cluster import DBSCAN\n",
    "from analyzeImage import analyzeImage as ai\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_param_file():\n",
    "    paramsFile = open('../code/gpu/debug/parameters.config', 'w')\n",
    "    paramsFile.write(\n",
    "    \"\"\"Debug ................ : 1\n",
    "    PSF Sigma ............ : 1.0\n",
    "    Mask Threshold ....... : 0.75\n",
    "    Mask Penalty ......... : -0.05\n",
    "    Angles to Search ..... : 120\n",
    "    Minimum Angle ........ : 0.0\n",
    "    Maximum Angle ........ : 6.283\n",
    "    Velocities to Search . : 90\n",
    "    Minimum Velocity ..... : 24.\n",
    "    Maximum Velocity ..... : 600.\n",
    "    Psi/Phi to file ...... : 1\n",
    "    Source Images Path ... : ../../{source}/\n",
    "    Psi Images Path ...... : ../../{psi}/\n",
    "    Phi Images Path....... : ../../{phi}/\n",
    "    Results Path ......... : ../../../data/results/{name}.txt\n",
    "    \"\"\".format( source=real_image_path, psi=psi_image_path, phi=phi_image_path, name=results_name ))\n",
    "    paramsFile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trim_on_lc(clustered_results, im_array, image_times):\n",
    "    \n",
    "    f_results = clustered_results        \n",
    "    keep_results = []\n",
    "    light_curves = []\n",
    "    ai_2 = analyzeImage()\n",
    "    \n",
    "    for current in range(len(f_results)):\n",
    "        traj_coords = ai_2.calc_traj_coords(f_results[current], image_times)\n",
    "        light_curve = [im_array[x, traj_coords[x,1], traj_coords[x,0]] for x in range(len(im_array))]\n",
    "        if np.max(light_curve) < 10*np.median(light_curve):\n",
    "            keep_results.append(current)\n",
    "            light_curves.append(light_curve)\n",
    "        \n",
    "    return f_results[keep_results], light_curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_stamps(im_array, kept_results, image_times):\n",
    "    \n",
    "    f_results = kept_results#filtered_results\n",
    "    postage_stamps = []\n",
    "    ai_2 = analyzeImage()\n",
    "    for imNum in range((len(f_results))):\n",
    "        current = imNum#best_targets[imNum]\n",
    "        ps = ai_2.createPostageStamp(im_array,\n",
    "                                  list(f_results[['t0_x', 't0_y']][current]),\n",
    "                                  np.array(list(f_results[['v_x', 'v_y']][current])), \n",
    "                                  image_times, [25., 25.])\n",
    "        postage_stamps.append(ps[0])\n",
    "                       \n",
    "    return postage_stamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_results():\n",
    "    #Load results\n",
    "    raw_results = np.genfromtxt('../data/results/HITS1.txt', names=True)\n",
    "    \n",
    "    #Load times\n",
    "    image_mjd = []\n",
    "\n",
    "    for filename in sorted(os.listdir(real_image_path)):\n",
    "        hdulist = fits.open(os.path.join(real_image_path, filename))\n",
    "        image_mjd.append(hdulist[0].header['MJD'])\n",
    "\n",
    "    image_mjd = np.array(image_mjd)\n",
    "    image_times = image_mjd - image_mjd[0]\n",
    "    \n",
    "    #Load images\n",
    "    hdulist = fits.open(os.path.join(real_image_path, os.listdir(real_image_path)[0]))\n",
    "    num_images = len(os.listdir(real_image_path))\n",
    "    image_shape = np.shape(hdulist[1].data)\n",
    "    im_array = np.zeros((num_images, image_shape[0], image_shape[1]))\n",
    "\n",
    "\n",
    "    for idx, filename in list(enumerate(sorted(os.listdir(real_image_path)))):\n",
    "\n",
    "       # print( str('Loaded ' + filename))\n",
    "\n",
    "        image_file = os.path.join(real_image_path, filename)\n",
    "        hdulist = fits.open(image_file)\n",
    "        im_array[idx] = hdulist[1].data#*mask\n",
    "    \n",
    "    ai = analyzeImage()\n",
    "    \n",
    "    model = load_model('../data/kbmod_model.h5')\n",
    "    \n",
    "    results = raw_results[np.where(raw_results['likelihood'] >= 5.0)]\n",
    "    \n",
    "    filtered_results = ai.filter_results(im_array, results, image_times, model, chunk_size=5000)\n",
    "    \n",
    "    results_to_cluster = filtered_results\n",
    "    arg = dict(eps=0.03, min_samples=1, n_jobs=-1)\n",
    "    clustered_results = ai.clusterResults(results_to_cluster, dbscan_args=arg)#, im_array, image_times)\n",
    "    clustered_results =  results_to_cluster[np.array(clustered_results[1], dtype=np.int)]\n",
    "    \n",
    "    kept_results, light_curves = trim_on_lc(clustered_results, im_array, image_times)\n",
    "    stamps = create_stamps(im_array, kept_results, image_times)\n",
    "    return kept_results, light_curves, stamps, image_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    PSF Sigma ............  : 1.0\n",
      "    Mask Threshold .......  : 0.75\n",
      "    Mask Penalty .........  : -0.05\n",
      "    Angles to Search .....  : 120\n",
      "    Minimum Angle ........  : 0.0\n",
      "    Maximum Angle ........  : 6.283\n",
      "    Velocities to Search .  : 90\n",
      "    Minimum Velocity .....  : 24.\n",
      "    Maximum Velocity .....  : 600.\n",
      "    Psi/Phi to file ......  : 1\n",
      "    Source Images Path ...  : ../../../../HITS/trimmed_chip_01/Blind15A_01/search_nights//\n",
      "    Psi Images Path ......  : ../../../code/gpu/output-images/psi/\n",
      "    Phi Images Path.......  : ../../../code/gpu/output-images/phi/\n",
      "    Results Path .........  : ../../../data/results/HITS1.txt\n",
      "Using Kernel Size 5X5\n",
      "| 0.004 | 0.015 | 0.023 | 0.015 | 0.004 | \n",
      " ---------------------------------------\n",
      "| 0.015 | 0.058 | 0.093 | 0.058 | 0.015 | \n",
      " ---------------------------------------\n",
      "| 0.023 | 0.093 | 0.147 | 0.093 | 0.023 | \n",
      " ---------------------------------------\n",
      "| 0.015 | 0.058 | 0.093 | 0.058 | 0.015 | \n",
      " ---------------------------------------\n",
      "| 0.004 | 0.015 | 0.023 | 0.015 | 0.004 | \n",
      " ---------------------------------------\n",
      "97.532% of PSF contained within kernel\n",
      "Reading 4 images from ../../../../HITS/trimmed_chip_01/Blind15A_01/search_nights//\n",
      "\n",
      "Image times: 0.000 0.068 0.153 0.222 \n",
      "Masking images ... Done.\n",
      "Creating Psi and Phi ... Done. Took 154.106 ms per image\n",
      "Creating interleaved psi/phi buffer ... Done.\n",
      "Searching 10800 possible trajectories starting from 7700597 pixels... \n",
      "^C\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-9cffa3e8e10e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mkept_results\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight_curves\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstamps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_times\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprocess_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mfield_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkept_results\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mfield_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'field_num'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_num\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for chip_num in ['01', '03', '04', '05']:\n",
    "    chip_results = []\n",
    "    chip_lc = []\n",
    "    chip_stamps = []\n",
    "    chip_times = []\n",
    "    field_id = []\n",
    "    df = pd.DataFrame(columns=['t0_x', 't0_y', 'theta_par', 'theta_perp', 'v_x', \n",
    "                               'v_y', 'likelihood', 'est_flux', 'field_num'])\n",
    "    for field_num in xrange(1,57):\n",
    "        if field_num < 10:\n",
    "            real_image_path = str(\"../../HITS/trimmed_chip_\" + str(chip_num) + \n",
    "                                  \"/Blind15A_0\" + str(field_num) + \"/search_nights/\")\n",
    "        else:\n",
    "            real_image_path = str(\"../../HITS/trimmed_chip_\" + str(chip_num) + \n",
    "                                  \"/Blind15A_\" + str(field_num) + \"/search_nights/\")\n",
    "        results_name = \"HITS1\"\n",
    "        gpu_code_path = \"../code/gpu/\"\n",
    "        psi_image_path = gpu_code_path+\"output-images/psi\"\n",
    "        phi_image_path = gpu_code_path+\"output-images/phi\"\n",
    "        \n",
    "        write_param_file()\n",
    "        \n",
    "        !cd ~/cuda-workspace/kbmod/code/gpu/debug/; ./clearImages.sh\n",
    "        !cd ~/cuda-workspace/kbmod/code/gpu/debug/; ./CudaTracker\n",
    "        \n",
    "        try:\n",
    "            kept_results, light_curves, stamps, image_times = process_results()\n",
    "            field_df = pd.DataFrame.from_records(kept_results)\n",
    "            field_df['field_num'] = field_num\n",
    "            df = df.append(field_df)\n",
    "            for lc, stamp in zip(light_curves, stamps):\n",
    "                chip_lc.append(lc)\n",
    "                chip_stamps.append(stamp)\n",
    "                chip_times.append(image_times)\n",
    "                field_id.append(field_num)\n",
    "        except:\n",
    "            continue\n",
    "    df.to_csv(str(str(chip_num) + '_results.csv'), index=False)\n",
    "    fig = plt.figure(figsize=(8, 3*len(field_id)))\n",
    "    for lc, stamp, plot_num, image_time_set in zip(chip_lc, chip_stamps, np.arange(len(field_id)), chip_times):\n",
    "        fig.add_subplot(len(field_id),2,2*plot_num + 1)\n",
    "        plt.imshow(stamp, origin='lower', interpolation='None')\n",
    "        plt.title(str(field_id[plot_num]))\n",
    "        fig.add_subplot(len(field_id),2,2*plot_num + 2)\n",
    "        plt.plot(image_time_set, lc)\n",
    "        plt.xlabel('Time (days)')\n",
    "        plt.ylabel('Flux')\n",
    "        plt.tight_layout()\n",
    "    plt.savefig(str(str(chip_num) + '_stamps.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
